---
title: "K Nearest Neighbours (KNN)"
output:
  pdf_document: default
urlcolor: blue
---

# Short Intro

KNN (K Nearest Neighbours) is a non-parametric, lazy learning classification algorithm. Non-parametric means it does not make any assumptions on the underlying data distribution. Therefore, KNN should be one of the first choices for a classification problem when there is little or no prior knowledge about the data distribution. Lazy algorithm (as opposed to an eager algorithm) means it does not use the training data points to do any generalization. In other words, there is no explicit training phase.

In KNN, a given data point is classified based on the class of the nearest *k* neighbors. *k* is usually an odd number in case of binary classification. In order to find the closest neighbors, we calculate feature similarity distance (Euclidean, Manhattan, etc.).

The steps are the following:

1. Calculate the distance between the data points,
2. Find closest neighbors,
3. Choose a class of the majority of neighbors.   

```{r knitr-logo, fig.align='center', out.height="390px", echo=FALSE}
knitr::include_graphics(rep('images/knn-steps.png'))
```

KNN can be used for classification: the output is a class membership (predicts a class - a discrete value). An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors. It can also be used for regression: output is the value for the object (predicts continuous values). This value is the average (or median) of the values of its k nearest neighbors.

# Load and prepare data set

We will use the same data set (*Carseats*) as in the previous Lab. 
```{r}
# load ISLR package
library(ISLR)

# print dataset structure
str(Carseats)
```

As we did before, we will introduce a categorical (factor) variable *HighSales* to be used as the outcome variable (variable defining the class for each observation). If a sale is greater than the 3rd quartile (9.32), it qualifies as a high sale:

```{r}
# calculate 3rd quartile
sales.3Q <- quantile(Carseats$Sales, 0.75)

# create a new variable HighSales based on the value of the 3rd quartile
Carseats$HighSales <- ifelse(test = Carseats$Sales > sales.3Q,
                             yes = 'Yes',
                             no = 'No')

# convert HighSales from character to factor
Carseats$HighSales <- as.factor(Carseats$HighSales)
```

We'll remove the *Sales* variable, as we do not need it anymore.

```{r}
# remove the Sales variable
Carseats <- Carseats[,-1]
```

# Standardize numerical attributes

Recall that the *kNN* algorithm primarily works with numerical data. So, if we want to use categorical and/or binary variables, we have to transform them into numerical variables.

kNN is very sensitive to differences in the value range of predictor variables. This is because predictors with a wider range of values (e.g. *Price*) would diminish the influence of variables with significantly narrower range (e.g. *Education*). 

Let's check our variables and their value ranges.

```{r}
# print the summary of the dataset
summary(Carseats)
```

Value intervals differ for all variables. We should, obviously, rescale our numerical variables. 

Rescaling can be generally done in two ways:

* *Normalization* - reducing variable values to a common value range, typically [0,1]; this is often done using the formula: 

$$Z = \frac{X - min(X)}{max(X) - min(X)}$$

* *Standardization* - rescaling variables so that their *mean = 0* and *SD = 1*. For the variable X that is normally distributed, this is done by computing: 

$$Z = \frac{X - mean(X)}{SD(X)}$$

\begin{itemize}
  \item[] If the variable X is not normally distributed, standardization is typically done using median and inter-quartile range (IQR):
\end{itemize}

$$Z = \frac{X - median(X)}{IQR(X)}$$
\begin{itemize}
  \item[] , where $IQR(X) = Q3(X) - Q1(x)$.
\end{itemize}

Normalization should be avoided if (numerical) variables have outliers; standardization should be used instead. In the absence of outliers, either of the two can be used.

Let's check the presence of outliers in the *CompPrice* variable.

```{r}
# plot the boxplot for the CompPrice variable
boxplot(Carseats[,1])

# print the number of outliers in the CompPrice variable
length(boxplot.stats(Carseats[,1])$out)
```

Let's do the same for all numeric variables.

```{r}
# filter all numerica variables
numeric.vars <- c(1:5,7,8) # indices of numeric columns

# apply the function for returning the number of outliers for all numeric variables
apply(X = Carseats[,numeric.vars], # select numeric columns
      MARGIN = 2, # apply the function to columns
      FUN = function(x) {
        length(boxplot.stats(x)$out)
      }) # the function to be applied to each column
```

Only 2 variables (*CompPrice*, *Price*) have just a few outliers. Hence, either of the scaling methods can be used.

We will rescale our numerical variables by standardizing them (typical approach). To determine how to standardize the variables, we need to check their distribution (if they follow Normal distribution or not). 

We will use *Shapiro-Wilk test* to check for normality. The *null hypothesis* of this test is that a sample comes from a normally distributed population; if the test is not significant (p>0.05), we can assume that the null hypothesis holds.

```{r}
# apply the test to each numerical column (variable)
apply(X = Carseats[,numeric.vars], 
      MARGIN = 2, 
      FUN = shapiro.test)
```

Only *CompPrice* and *Price* are normally distributed. So, we will standardize *Price* and *CompPrice* using mean and SD, and for other variables, we'll use median and IQR. 

To do the scaling, we will use the *scale* function (from the base package).

```{r}
# get the documentation for the scale function
?scale
```

We'll start by rescaling variables that are not normally distributed.

```{r}
# select not-normally distributed numerical columns (variables)
carseats.st <- Carseats[, c(2,3,4,7,8)]

# apply the scalling function to each column
carseats.st <- apply(X = carseats.st, 
                     MARGIN = 2,
                     FUN = function(x){
                       scale(x, center = median(x), scale = IQR(x))
                     })

# since apply() f. returns a list, convert it to a data frame
carseats.st <- as.data.frame(carseats.st)
```

Then, we'll standardize and add normally distributed ones.

```{r}
# standardize the Price variable (and convert to vector)
carseats.st$Price <- as.vector(scale(x = Carseats$Price, center = TRUE, scale = TRUE))

# standardize the CompPrice variable (and convert to vector)
carseats.st$CompPrice <- as.vector(scale(x = Carseats$CompPrice, center = TRUE, scale = TRUE))
```

**Note:** the scale() f. returns a matrix with just one column; so, it is effectively a vector and we transform it into a vector using the as.vector() f.

Now, we need to handle binary and categorical variables.

# Transform factor (binary and categorical) variables

Transform binary variables into numerical.

```{r}
# transform the Urban variable to integer
carseats.st$Urban <- as.integer(Carseats$Urban)

# transform the US variable to integer
carseats.st$US <- as.integer(Carseats$US)
```

It is often considered more correct to first encode categorical variables as binary dummy variables, and then transform the resulting binary variables into numerical ones. However, for simplicity reasons, and since our categorical variable - *ShelveLoc* - is ordered, we will directly transform it into a numerical variable. 

First, let's check the order of *ShelveLoc* levels.
```{r}
# print the levels of the ShelveLoc variable
levels(Carseats$ShelveLoc)
```

Obviously, the order is not a 'natural' one. So, we need to change the order of levels.

```{r}
# update the order of levels for the ShelveLoc variable to: "Bad", "Medium", "Good"
Carseats$ShelveLoc <- factor(Carseats$ShelveLoc, levels = c("Bad", "Medium", "Good"))
levels(Carseats$ShelveLoc)
```

Now, we can transform the *ShelveLoc* into a numerical variable.

```{r}
# convert ShelveLoc into a numeric variable
carseats.st$ShelveLoc <- as.integer(Carseats$ShelveLoc)
```

**TASK**: Try to create dummy variables for *ShelveLoc* and build a model with these new variables; [this page](http://topepo.github.io/caret/pre-processing.html#dummy) shows how to create dummy variables using the *caret* package.

Finally, add the outcome (class) variable.

```{r}
# add the outcome variable HighSales
carseats.st$HighSales <- Carseats$HighSales
```

Examine the transformed data set.

```{r}
# print the structure of the data frame
str(carseats.st)
```

```{r}
# print the summary of the data frame
summary(carseats.st)
```


Now that we have prepared the data, we can proceed to create sets for training and testing.

# Create train and test data sets

We'll use the *caret* package for partitioning the dataset into train and test sets.

```{r message=FALSE}
# load the caret package
library(caret)
```

We'll take 80% of observations for the training set and the rest for the test set.

```{r}
# set seed
set.seed(1010)

# create train and test sets
train.indices <- createDataPartition(carseats.st$HighSales, p = 0.8, list = FALSE)
train.data <- carseats.st[train.indices,]
test.data <- carseats.st[-train.indices,]
```

# Model building

To build a kNN classification model, we will use the *knn* f. from the *class* package.

```{r}
# load the class package
library(class)

?knn
```

As the knn() function description indicates, we need to provide the function with:

* training data without the class variable,
* test data without the class variable,
* class values for the training set,
* a number of neighbors to consider.

```{r}
# createa a knn model with k=5
knn.pred <- knn(train = train.data[,-11], 
                test = test.data[,-11],
                cl = train.data$HighSales,
                k = 5) # 5 is chosen here just as a random guess
```

The result of the *knn* f. are, in fact, predictions on the test set.

```{r}
# print several predictions
head(knn.pred)
```

To evaluate the results, we'll first create the confusion matrix:

```{r}
# create the confusion matrix
knn.cm <- table(true = test.data$HighSales, predicted = knn.pred)
knn.cm
```

We'll use the function for computing the evaluation metrics.

```{r}
# function for computing evaluation metrix
compute.eval.metrics <- function(cmatrix) {
  TP <- cmatrix[1,1] # true positive
  TN <- cmatrix[2,2] # true negative
  FP <- cmatrix[2,1] # false positive
  FN <- cmatrix[1,2] # false negative
  acc = sum(diag(cmatrix)) / sum(cmatrix)
  precision <- TP / (TP + FP)
  recall <- TP / (TP + FN)
  F1 <- 2*precision*recall / (precision + recall)
  c(accuracy = acc, precision = precision, recall = recall, F1 = F1)
}
```

Compute the evaluation metrics based on the confusion matrix.

```{r}
# compute the evaluation metrics
knn.eval <- compute.eval.metrics(knn.cm)
knn.eval
```

Not bad, but we might be able to do better by choosing another value for k.

We made a guess about the number of neighbors, and might not have made the best guess. Instead of guessing, we'll cross-validate models with several different values for k, and see which one gives the best performance; then, we'll use the test set to evaluate the model that proves to be the best on cross-validation.

For finding the optimal value for *k* through 10-fold cross-validation, we will use the **caret** package and the **e1071** package (internally called by the *caret* package).

```{r message=FALSE}
# load e1071 library
library(e1071)
```

```{r}
# define cross-validation (cv) parameters; we'll perform 10-fold cross-validation
numFolds = trainControl( method = "cv", number = 10)
```

Then, define the range of *k* values to examine in the cross-validation; we'll take odd numbers between 3 and 25. Recall that in case of binary classification, it is recommended to choose an odd number for *k*.

```{r}
# define the range for the k values to examine in the cross-validation
cpGrid = expand.grid(.k = seq(from=3, to = 25, by = 2))
```

Now, train the model through cross-validation.

```{r}
# since cross-validation is a probabilistic process, it is advisable to set the seed so that we can replicate the results
set.seed(1010)

# run the cross-validation
knn.cv <- train(HighSales ~ ., 
                data = train.data,
                method = "knn", 
                trControl = numFolds,
                tuneGrid = cpGrid)
knn.cv
```

We can get a better insight into the cross-validation results by plotting them.

```{r}
# plot the cross-validation results
plot(knn.cv)
```

k=9 proved to be the best value. Let's build a model with that value for k.

```{r}
# build a new model with k=9
knn.pred2 <- knn(train = train.data[,-11],
                  test = test.data[,-11],
                  cl = train.data$HighSales,
                  k = 9)
```

Create the confusion matrix for the new predictions.

```{r}
# create the confusion matrix
knn.cm2 <- table(true = test.data$HighSales, predicted = knn.pred2)
knn.cm2
```

Compute evaluation measures.

```{r}
# compute the evaluation metrics
knn.eval2 <- compute.eval.metrics(knn.cm2)
knn.eval2
```

This model seems to be better than the previous one, but let's compare the metrics of the two models to check how the new model fares
```{r}
# compare the evaluation metrics for knn1 and knn2 models
data.frame(rbind(knn.eval, knn.eval2), row.names = c("knn 1", "knn 2"))
```

The first model (*knn1*) is better in term of precision, but weaker with respect to recall.

**TASK** Create a new model by taking only a subset of variables, for example, those that proved relevant in the DT model and compare the performance with the previously built models.

Potentially useful articles:

* [kNN Using caret R package](http://rpubs.com/njvijay/16444)
* [Knn classifier implementation in R with caret package](http://dataaspirant.com/2017/01/09/knn-implementation-r-using-caret-package/)